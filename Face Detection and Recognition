import cv2
import numpy as np

# Load Haar cascade for face detection
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

# Function to process and resize face images
def process_face_image(image_path, size=(200, 200)):
    image = cv2.imread(image_path)
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

    if len(faces) > 0:
        (x, y, w, h) = faces[0]
        face = gray_image[y:y + h, x:x + w]
        face = cv2.resize(face, size)
        return face
    else:
        raise Exception(f"No face found in image {image_path}")

# Load and process Aadhaar card images
aadhaar_images = {
    "image.jpg": "Abhijna"
    # Add more image paths and corresponding names here
}

aadhaar_faces = {}
for image_path, name in aadhaar_images.items():
    try:
        face = process_face_image(image_path)
        aadhaar_faces[name] = face
    except Exception as e:
        print(e)

# Start video capture
video_cap = cv2.VideoCapture(0)

while True:
    ret, video_data = video_cap.read()
    if not ret:
        break

    # Convert video frame to grayscale
    gray_video_data = cv2.cvtColor(video_data, cv2.COLOR_BGR2GRAY)

    # Detect faces in the video frame
    faces = face_cascade.detectMultiScale(
        gray_video_data,
        scaleFactor=1.1,
        minNeighbors=5,
        minSize=(30, 30),
        flags=cv2.CASCADE_SCALE_IMAGE
    )

    # Draw rectangle around each detected face and perform face matching
    for (x, y, w, h) in faces:
        cv2.rectangle(video_data, (x, y), (x + w, y + h), (0, 255, 0), 2)

        # Extract the face region of interest (ROI)
        face_roi = gray_video_data[y:y + h, x:x + w]
        face_roi = cv2.resize(face_roi, (200, 200))  # Resize to the same size as Aadhaar faces

        match_found = False
        for name, aadhaar_face in aadhaar_faces.items():
            if face_roi.shape == aadhaar_face.shape:
                mse = np.sum((face_roi - aadhaar_face) ** 2) / float(face_roi.shape[0] * face_roi.shape[1])
                threshold = 1000  # Adjust this threshold based on your requirements
                if mse < threshold:
                    cv2.putText(video_data, f"Match: {name}", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)
                    match_found = True
                    break

        if not match_found:
            cv2.putText(video_data, "No Match", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)

    # Display the video frame with rectangles
    cv2.imshow("video_live", video_data)

    # Break the loop if 'a' key is pressed
    if cv2.waitKey(10) == ord("a"):
        break

# Release the video capture object and close all OpenCV windows
video_cap.release()
cv2.destroyAllWindows()
